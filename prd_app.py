# -*- coding: utf-8 -*-
"""
AI-PRD ç”Ÿæˆæ©Ÿå™¨äºº - Streamlit ç‰ˆæœ¬
ä½¿ç”¨ç´” Agent æ¨¡å¼çš„éœ€æ±‚æ”¶é›†æµç¨‹
"""

import streamlit as st
import os
import asyncio
import json
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv
import logging

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv(override=True)

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å°å…¥ Agents
from agents.requirement_coordinator import RequirementCoordinator
from agents.multi_version_generator import MultiVersionGenerator
from agents.sprint_prd_agent import SprintPRDAgent
from agents.tdd_prd_agent import TDDPRDAgent
from agents.bdd_prd_agent import BDDPRDAgent
from agents.ddd_prd_agent import DDDPRDAgent

# é é¢é…ç½®
st.set_page_config(
    page_title="AI-PRD ç”Ÿæˆå™¨",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }

    .progress-step {
        display: inline-block;
        padding: 8px 16px;
        margin: 4px;
        border-radius: 20px;
        font-weight: bold;
    }

    .step-active {
        background-color: #28a745;
        color: white;
    }

    .step-completed {
        background-color: #6c757d;
        color: white;
    }

    .step-pending {
        background-color: #f8f9fa;
        color: #6c757d;
        border: 2px solid #dee2e6;
    }

    .risk-high {
        background-color: #f8d7da;
        border-left: 5px solid #dc3545;
        padding: 10px;
        margin: 5px 0;
    }

    .risk-medium {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 10px;
        margin: 5px 0;
    }

    .risk-low {
        background-color: #d4edda;
        border-left: 5px solid #28a745;
        padding: 10px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– session state
def init_session_state():
    """åˆå§‹åŒ– session state è®Šæ•¸"""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "current_prd" not in st.session_state:
        st.session_state.current_prd = ""

    if "selected_mode" not in st.session_state:
        st.session_state.selected_mode = None  # ç”¨æˆ¶å¿…é ˆæ‰‹å‹•é¸æ“‡

    if "review_results" not in st.session_state:
        st.session_state.review_results = None

    if "version_comparison" not in st.session_state:
        st.session_state.version_comparison = None

    if "api_key_validated" not in st.session_state:
        st.session_state.api_key_validated = False

    # åˆå§‹åŒ–ç”¨æˆ¶è¼¸å…¥çš„ API Key
    if "user_api_key" not in st.session_state:
        st.session_state.user_api_key = os.getenv("OPENAI_API_KEY", "")

    if "prd_check_results" not in st.session_state:
        st.session_state.prd_check_results = None

    # åˆå§‹åŒ–çµæ§‹åŒ–éœ€æ±‚æ•¸æ“š
    if "requirements" not in st.session_state:
        st.session_state.requirements = {
            "stage_0": {},
            "stage_1": {},
            "stage_2": {}
        }

    # åˆå§‹åŒ–éœ€æ±‚æ”¶é›†å®Œæˆç‹€æ…‹ï¼ˆä¸ä¾è³´æ–‡å­—åŒ¹é…ï¼‰
    if "requirements_completed" not in st.session_state:
        st.session_state.requirements_completed = False

    # åˆå§‹åŒ–ç•¶å‰æ¨™ç±¤é ç´¢å¼•
    if "current_tab" not in st.session_state:
        st.session_state.current_tab = 0  # 0: éœ€æ±‚æ”¶é›†, 1: åˆç‰ˆPRD, 2: å¤šç‰ˆæœ¬PRD

    # åˆå§‹åŒ– RequirementCoordinatorï¼ˆç´” Agent æ¨¡å¼ï¼‰
    if "coordinator" not in st.session_state:
        try:
            st.session_state.coordinator = RequirementCoordinator()
            # ç•°æ­¥åˆå§‹åŒ– session
            run_async(st.session_state.coordinator.initialize())
            # ç²å–åˆå§‹æ­¡è¿æ¶ˆæ¯
            welcome_msg = run_async(st.session_state.coordinator.send_message("é–‹å§‹"))
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": welcome_msg
            })
            logger.info("RequirementCoordinator åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ– RequirementCoordinator å¤±æ•—: {str(e)}")
            st.error(f"åˆå§‹åŒ–å¤±æ•—: {str(e)}")

def display_requirements_guide():
    """é¡¯ç¤ºéœ€æ±‚æ”¶é›†æŒ‡å—"""
    st.markdown("""
<div style="background-color: #d1ecf1; padding: 15px; border-radius: 5px; border-left: 5px solid #0c5460;">

ğŸ“‹ **éœ€è¦æ”¶é›†çš„ä¿¡æ¯ï¼š**

**1. æ ¸å¿ƒå•é¡Œ**
<span style="color: red;">â€¢ ä½ æƒ³è§£æ±ºä»€éº¼å•é¡Œï¼Ÿ â­</span>
â€¢ ç¾åœ¨çš„ç—›é»æœ‰å¤šç—›ï¼Ÿï¼ˆ1-10åˆ†ï¼‰
â€¢ ä¸è§£æ±ºæœƒæ€æ¨£ï¼Ÿ

**2. ç”¨æˆ¶è¼ªå»“**
<span style="color: red;">â€¢ èª°æœƒç”¨é€™å€‹ç”¢å“ï¼Ÿ â­</span>
â€¢ ä»–å€‘ç¾åœ¨æ€éº¼è§£æ±ºé€™å€‹å•é¡Œï¼Ÿ
â€¢ ä»–å€‘é¡˜æ„ä»˜å¤šå°‘éŒ¢è§£æ±ºï¼Ÿ

**3. æˆåŠŸå®šç¾©**
â€¢ æ€æ¨£ç®—æˆåŠŸï¼Ÿ
<span style="color: red;">â€¢ æœ‰ä»€éº¼å¯ä»¥é‡åŒ–çš„æŒ‡æ¨™ï¼Ÿ â­</span>
<span style="color: red;">â€¢ æœ€å°å¯è¡Œç”¢å“è¦æœ‰å“ªäº›åŠŸèƒ½ï¼Ÿ â­</span>

</div>
    """, unsafe_allow_html=True)

    st.markdown("""
<div style="background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 5px solid #ffc107; margin-top: 15px;">

ğŸ¯ **PRD é–‹ç™¼æ¨¡å¼å»ºè­°ï¼š**

â€¢ **Sprint æ¨¡å¼ï¼ˆAI-DLC å¿«é€Ÿé–‹ç™¼ï¼‰**
  é©åˆï¼š48-72å°æ™‚ MVPã€å–®äººé–‹ç™¼ã€å¿«é€ŸåŸå‹é©—è­‰
  é—œéµè©ï¼šmvpã€å¿«é€Ÿã€é€±æœ«ã€åŸå‹ã€é©—è­‰

â€¢ **TDD æ¨¡å¼ï¼ˆæ¸¬è©¦é©…å‹•é–‹ç™¼ï¼‰**
  é©åˆï¼šæŠ€è¡“ç”¢å“ã€API é–‹ç™¼ã€é«˜å“è³ªè¦æ±‚
  é—œéµè©ï¼šapiã€sdkã€æŠ€è¡“ã€æ¶æ§‹ã€æ•ˆèƒ½

â€¢ **BDD æ¨¡å¼ï¼ˆè¡Œç‚ºé©…å‹•é–‹ç™¼ï¼‰**
  é©åˆï¼šç”¨æˆ¶å°å‘ç”¢å“ã€B2C æ‡‰ç”¨ã€è·¨éƒ¨é–€å”ä½œ
  é—œéµè©ï¼šç”¨æˆ¶ã€é«”é©—ã€ç•Œé¢ã€æµç¨‹ã€æ¥­å‹™

â€¢ **DDD æ¨¡å¼ï¼ˆé ˜åŸŸé©…å‹•è¨­è¨ˆï¼‰**
  é©åˆï¼šä¼æ¥­ç´šæ‡‰ç”¨ã€è¤‡é›œç³»çµ±ã€å¤šé ˜åŸŸæ•´åˆ
  é—œéµè©ï¼šä¼æ¥­ã€è¤‡é›œã€æ•´åˆã€å¤§å‹ã€ç³»çµ±æ€§

</div>
    """, unsafe_allow_html=True)

    st.caption("""
ğŸ’¡ **ç›´æ¥ç”Ÿæˆ PRD çš„ä½¿ç”¨æ–¹å¼ï¼š**
â€¢ å¿…é ˆå…ˆå›ç­”ä¸Šè¿° 4 å€‹ç´…è‰²æ˜Ÿè™Ÿï¼ˆâ­ï¼‰æ¨™è¨˜çš„å¿…å¡«å•é¡Œ
â€¢ å®Œæˆå¿…å¡«é …å¾Œï¼Œå¯é»æ“Šã€Œç›´æ¥ç”Ÿæˆ PRDã€æŒ‰éˆ•å¿«é€Ÿç”Ÿæˆæ–‡æª”
â€¢ å»ºè­°ï¼šå®Œæ•´å›ç­”æ‰€æœ‰ 9 å€‹å•é¡Œå¯ç²å¾—æ›´å°ˆæ¥­ã€æ›´è©³ç´°çš„ PRD
    """)

def run_async(coro):
    """
    å®‰å…¨åœ°é‹è¡Œç•°æ­¥å”ç¨‹ï¼Œè™•ç†äº‹ä»¶å¾ªç’°è¡çª

    Args:
        coro: ç•°æ­¥å”ç¨‹

    Returns:
        å”ç¨‹çš„è¿”å›å€¼
    """
    try:
        # å˜—è©¦ç²å–ç¾æœ‰äº‹ä»¶å¾ªç’°
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœå¾ªç’°æ­£åœ¨é‹è¡Œï¼Œä½¿ç”¨ nest_asyncioï¼ˆStreamlit ç’°å¢ƒï¼‰
            import nest_asyncio
            nest_asyncio.apply()
            return loop.run_until_complete(coro)
        else:
            # å¾ªç’°æœªé‹è¡Œï¼Œç›´æ¥ä½¿ç”¨ asyncio.run
            return asyncio.run(coro)
    except RuntimeError:
        # æ²’æœ‰äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„
        return asyncio.run(coro)

async def get_ai_response(user_input: str) -> str:
    """é€é RequirementCoordinator ç²å– AI å›æ‡‰"""
    try:
        response = await st.session_state.coordinator.send_message(user_input)
        return response
    except Exception as e:
        logger.error(f"ç²å– AI å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

async def validate_api_key(api_key: str, api_base: str = None) -> tuple[bool, str]:
    """
    é©—è­‰ OpenAI API Key æ˜¯å¦æœ‰æ•ˆ

    Args:
        api_key: API Key
        api_base: API åŸºç¤ URLï¼ˆå¯é¸ï¼‰

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, éŒ¯èª¤è¨Šæ¯æˆ–æˆåŠŸè¨Šæ¯)
    """
    try:
        from google.adk.models.lite_llm import LiteLlm
        from google.genai import types

        # å‰µå»ºæ¸¬è©¦æ¨¡å‹
        test_model = LiteLlm(
            model="gpt-4o",
            api_base=api_base or os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
            api_key=api_key
        )

        # ç™¼é€ç°¡å–®çš„æ¸¬è©¦è«‹æ±‚
        test_content = types.Content(
            role='user',
            parts=[types.Part(text="Hello")]
        )

        response = test_model.generate_content(contents=[test_content])

        # å¦‚æœèƒ½ç²å¾—å›æ‡‰ï¼Œèªªæ˜ API Key æœ‰æ•ˆ
        if response and response.text:
            return True, "API Key é©—è­‰æˆåŠŸï¼"
        else:
            return False, "API Key é©—è­‰å¤±æ•—ï¼šç„¡æ³•ç²å–å›æ‡‰"

    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API Key ç„¡æ•ˆï¼šæˆæ¬Šå¤±æ•—"
        elif "quota" in error_msg.lower():
            return False, "API Key é…é¡å·²ç”¨å®Œ"
        elif "timeout" in error_msg.lower():
            return False, "è«‹æ±‚è¶…æ™‚ï¼šè«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥"
        else:
            return False, f"é©—è­‰å¤±æ•—ï¼š{error_msg}"

async def generate_prd_with_agent(mode: str, requirements: Dict[str, Any]) -> str:
    """
    æ ¹æ“šé¸å®šçš„é–‹ç™¼æ¨¡å¼èª¿ç”¨å°æ‡‰çš„ PRD Agent ç”Ÿæˆ PRD

    Args:
        mode: é–‹ç™¼æ¨¡å¼å­—ç¬¦ä¸²ï¼ˆå¦‚ "ä¸€èˆ¬é–‹ç™¼ (AI-DLC Sprint)"ï¼‰
        requirements: çµæ§‹åŒ–éœ€æ±‚å­—å…¸

    Returns:
        ç”Ÿæˆçš„ PRD å…§å®¹
    """
    try:
        logger.info(f"é–‹å§‹ä½¿ç”¨ {mode} æ¨¡å¼ç”Ÿæˆ PRD...")

        # æ ¹æ“šæ¨¡å¼é¸æ“‡å°æ‡‰çš„ Agent
        if "Sprint" in mode or "ä¸€èˆ¬é–‹ç™¼" in mode:
            agent = SprintPRDAgent()
            prd = await agent.generate_prd(requirements)
        elif "TDD" in mode or "æ¸¬è©¦é©…å‹•" in mode:
            agent = TDDPRDAgent()
            prd = await agent.generate_prd(requirements)
        elif "BDD" in mode or "è¡Œç‚ºé©…å‹•" in mode:
            agent = BDDPRDAgent()
            prd = await agent.generate_prd(requirements)
        elif "DDD" in mode or "é ˜åŸŸé©…å‹•" in mode:
            agent = DDDPRDAgent()
            prd = await agent.generate_prd(requirements)
        else:
            # é è¨­ä½¿ç”¨ Sprint æ¨¡å¼
            logger.warning(f"æœªçŸ¥çš„é–‹ç™¼æ¨¡å¼: {mode}ï¼Œä½¿ç”¨é è¨­çš„ Sprint æ¨¡å¼")
            agent = SprintPRDAgent()
            prd = await agent.generate_prd(requirements)

        logger.info(f"PRD ç”Ÿæˆå®Œæˆï¼Œé•·åº¦: {len(prd)} å­—ç¬¦")
        return prd

    except Exception as e:
        logger.error(f"ç”Ÿæˆ PRD æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return f"""# ç”¢å“éœ€æ±‚æ–‡æª” (PRD) - {mode}

## éŒ¯èª¤æç¤º
ç”Ÿæˆ PRD æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}

è«‹æª¢æŸ¥ï¼š
1. OpenAI API Key æ˜¯å¦æ­£ç¢ºè¨­ç½®
2. ç¶²çµ¡é€£æ¥æ˜¯å¦æ­£å¸¸
3. éœ€æ±‚æ•¸æ“šæ˜¯å¦å®Œæ•´

æ‚¨å¯ä»¥å˜—è©¦é‡æ–°ç”Ÿæˆæˆ–è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚
"""

def main():
    """ä¸»æ‡‰ç”¨ç¨‹å¼"""
    # åˆå§‹åŒ–
    init_session_state()

    # ä¸»æ¨™é¡Œ
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ¤– AI-PRD ç”Ÿæˆå™¨</h1>
        <p>å¾éœ€æ±‚æ”¶é›†åˆ°å°ˆæ¥­ PRDï¼Œä¸€ç«™å¼è§£æ±ºæ–¹æ¡ˆ</p>
    </div>
    """, unsafe_allow_html=True)

    # å´é‚Šæ¬„è¨­ç½®
    with st.sidebar:
        st.title("ğŸ”§ è¨­ç½®")

        # API Key ç®¡ç†
        st.subheader("OpenAI API Key")

        # å¦‚æœå·²æœ‰ API Keyï¼Œé¡¯ç¤ºç‹€æ…‹å’Œæ“ä½œæŒ‰éˆ•
        if st.session_state.user_api_key:
            # é¡¯ç¤ºéƒ¨åˆ† API Keyï¼ˆå‰ 7 å­—ç¬¦...å¾Œ 4 å­—ç¬¦ï¼‰
            key = st.session_state.user_api_key
            if len(key) > 15:
                display_key = f"{key[:7]}...{key[-4:]}"
            else:
                display_key = f"{key[:4]}***"

            st.success(f"âœ… å·²è¨­ç½®ï¼š{display_key}")

            # æ“ä½œæŒ‰éˆ•
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ”„ æ›´æ›", use_container_width=True, key="change_api_key"):
                    st.session_state.user_api_key = ""
                    st.session_state.api_key_validated = False
                    st.rerun()

            with col2:
                if st.button("âœ… é©—è­‰", use_container_width=True, key="verify_api_key"):
                    with st.spinner("é©—è­‰ä¸­..."):
                        is_valid, message = run_async(validate_api_key(st.session_state.user_api_key))
                        if is_valid:
                            st.session_state.api_key_validated = True
                            os.environ["OPENAI_API_KEY"] = st.session_state.user_api_key
                            st.success(message)
                        else:
                            st.session_state.api_key_validated = False
                            st.error(message)

        else:
            # é¡¯ç¤ºè¼¸å…¥æ¡†
            st.info("ğŸ’¡ è«‹è¼¸å…¥æ‚¨çš„ OpenAI API Key")

            new_api_key = st.text_input(
                "è¼¸å…¥ API Key",
                type="password",
                placeholder="sk-...",
                help="è¼¸å…¥å®Œæˆå¾Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•ä¿å­˜",
                label_visibility="collapsed",
                key="new_api_key_input"
            )

            if st.button("ğŸ’¾ ä¿å­˜", type="primary", use_container_width=True, key="save_api_key"):
                if new_api_key and new_api_key.strip():
                    # ä¿å­˜ä¸¦é©—è­‰
                    with st.spinner("æ­£åœ¨é©—è­‰ API Key..."):
                        is_valid, message = run_async(validate_api_key(new_api_key.strip()))
                        if is_valid:
                            st.session_state.user_api_key = new_api_key.strip()
                            st.session_state.api_key_validated = True
                            os.environ["OPENAI_API_KEY"] = new_api_key.strip()
                            st.success(f"âœ… {message}")
                            st.rerun()
                        else:
                            st.error(f"âŒ {message}")
                else:
                    st.warning("âš ï¸ è«‹è¼¸å…¥ API Key")

        st.divider()

        # é–‹ç™¼æ¨¡å¼é¸æ“‡
        st.subheader("é–‹ç™¼æ¨¡å¼")

        mode_options = ["ä¸€èˆ¬é–‹ç™¼ (AI-DLC Sprint)", "TDD (æ¸¬è©¦é©…å‹•)", "BDD (è¡Œç‚ºé©…å‹•)", "DDD (é ˜åŸŸé©…å‹•)"]

        # å¦‚æœé‚„æ²’é¸æ“‡ï¼Œé¡¯ç¤ºæç¤º
        if st.session_state.selected_mode is None:
            default_index = 0
            st.info("ğŸ’¡ è«‹é¸æ“‡ PRD é–‹ç™¼æ¨¡å¼")
        else:
            # æ‰¾åˆ°ç•¶å‰é¸æ“‡çš„ç´¢å¼•
            try:
                default_index = mode_options.index(st.session_state.selected_mode)
            except ValueError:
                default_index = 0

        mode = st.selectbox(
            "é¸æ“‡é–‹ç™¼æ¨¡å¼",
            mode_options,
            index=default_index,
            help="""
            - Sprintï¼š48-72å°æ™‚å¿«é€Ÿ MVPï¼Œé©åˆå–®äººé–‹ç™¼è€…
            - TDDï¼šé©åˆæŠ€è¡“ç”¢å“ï¼Œå“è³ªå„ªå…ˆ
            - BDDï¼šé©åˆç”¨æˆ¶ç”¢å“ï¼Œè·¨éƒ¨é–€å”ä½œ
            - DDDï¼šé©åˆè¤‡é›œç³»çµ±ï¼Œé ˜åŸŸå»ºæ¨¡
            """
        )
        st.session_state.selected_mode = mode

    # ä¸»è¦å…§å®¹ï¼šä¸‰å€‹æ¨™ç±¤é 
    tab1, tab2, tab3 = st.tabs(["ğŸ“ éœ€æ±‚æ”¶é›†", "ğŸ“‹ åˆç‰ˆPRD", "ğŸ“Š å¤šç‰ˆæœ¬PRD"])

    with tab1:
        st.header("ğŸ“ éœ€æ±‚æ”¶é›†å°è©±")

        # éœ€æ±‚æ”¶é›†æŒ‡å—
        display_requirements_guide()

        st.divider()

        # éœ€æ±‚æ”¶é›†å®Œæˆæç¤ºï¼ˆä½¿ç”¨ç‹€æ…‹è®Šé‡ï¼‰
        if st.session_state.requirements_completed:
            st.success("ğŸ‰ æ‰€æœ‰éœ€æ±‚æ”¶é›†å®Œæˆï¼å¯ä»¥åœ¨ã€åˆç‰ˆPRDã€æ¨™ç±¤æŸ¥çœ‹ç”Ÿæˆçš„ PRDã€‚")

        # å°è©±æ­·å²é¡¯ç¤ºå’Œè¼¸å…¥æ•´åˆç‚ºä¸€å€‹å°è©±æ¡†
        st.subheader("å°è©±è¨˜éŒ„")

        # ä½¿ç”¨ container é…åˆ height è¨­ç½®å‰µå»ºå¯æ»¾å‹•çš„å°è©±æ¡†
        chat_container = st.container(height=600)

        with chat_container:
            for message in st.session_state.chat_history:
                if message["role"] == "user":
                    st.chat_message("user").write(message["content"])
                else:
                    st.chat_message("assistant").write(message["content"])

        # è¼¸å…¥æ¡†æ”¾åœ¨å°è©±æ¡†ä¸‹æ–¹
        st.markdown("### ğŸ’¬ è¼¸å…¥æ‚¨çš„å›ç­”")
        user_input = st.text_area(
            "è«‹è¼¸å…¥æ‚¨çš„å›ç­”ï¼š",
            height=100,
            key="user_input",
            placeholder="è«‹è¼¸å…¥æ‚¨çš„å›ç­”ï¼ŒæŒ‰ Ctrl+Enter æˆ–é»æ“Šä¸‹æ–¹ç™¼é€æŒ‰éˆ•...",
            label_visibility="collapsed"
        )

        col1, col2, col3 = st.columns([1, 1.5, 2.5])
        with col1:
            send_button = st.button("ğŸ“¤ ç™¼é€", type="primary", use_container_width=True)
        with col2:
            generate_prd_button = st.button("ğŸ“‹ ç›´æ¥ç”Ÿæˆ PRD", type="secondary", use_container_width=True)

        if send_button and user_input and user_input.strip():
            # ä¿å­˜ç”¨æˆ¶è¼¸å…¥
            message_to_send = user_input.strip()

            # æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯åˆ°æ­·å²
            st.session_state.chat_history.append({
                "role": "user",
                "content": message_to_send
            })

            # é€é coordinator ç²å– AI å›æ‡‰
            with st.spinner("æ€è€ƒä¸­..."):
                ai_response = run_async(get_ai_response(message_to_send))

            # æ·»åŠ  AI å›æ‡‰åˆ°æ­·å²
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": ai_response
            })

            # æ¸…ç©ºè¼¸å…¥æ¡†ï¼ˆé€éåˆªé™¤ session_state ä¸­çš„ keyï¼‰
            if "user_input" in st.session_state:
                del st.session_state["user_input"]

            st.rerun()

        # ç›´æ¥ç”Ÿæˆ PRD æŒ‰éˆ•é‚è¼¯
        if generate_prd_button:
            # æª¢æŸ¥æ˜¯å¦æœ‰å°è©±è¨˜éŒ„ï¼ˆè‡³å°‘å›ç­”äº†ä¸€äº›å•é¡Œï¼‰
            user_messages = [msg for msg in st.session_state.chat_history if msg.get("role") == "user"]

            if len(user_messages) < 4:
                # å°è©±å¤ªå°‘ï¼Œæç¤ºç”¨æˆ¶
                st.error("âŒ è«‹è‡³å°‘å›ç­” 4 å€‹é—œéµå•é¡Œå¾Œå†ç”Ÿæˆ PRD")
            else:
                with st.spinner("æ­£åœ¨æå–çµæ§‹åŒ–éœ€æ±‚..."):
                    # æå–çµæ§‹åŒ–éœ€æ±‚
                    requirements = run_async(
                        st.session_state.coordinator.extract_requirements(st.session_state.chat_history)
                    )
                    st.session_state.requirements = requirements

                    # æª¢æŸ¥æ˜¯å¦å®Œæ•´
                    is_complete = st.session_state.coordinator.is_requirements_complete(requirements)

                    if is_complete:
                        st.session_state.requirements_completed = True
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": "âœ… éœ€æ±‚æ”¶é›†å®Œæˆï¼å·²æˆåŠŸæå–çµæ§‹åŒ–éœ€æ±‚ã€‚è«‹åœ¨å´é‚Šæ¬„é¸æ“‡é–‹ç™¼æ¨¡å¼ï¼Œç„¶å¾Œå‰å¾€ã€åˆç‰ˆPRDã€æ¨™ç±¤ç”Ÿæˆæ–‡æª”ã€‚"
                        })
                        st.success("ğŸ‰ éœ€æ±‚æ”¶é›†å®Œæˆï¼è«‹é»æ“Šä¸Šæ–¹ã€ŒğŸ“‹ åˆç‰ˆPRDã€æ¨™ç±¤æŸ¥çœ‹ç”Ÿæˆçš„ PRDã€‚")
                    else:
                        st.warning("âš ï¸ éœ€æ±‚ä¿¡æ¯ä¸å¤ å®Œæ•´ï¼Œå»ºè­°è£œå……ä»¥ä¸‹å¿…å¡«ä¿¡æ¯ï¼š")
                        if not requirements.get("stage_0", {}).get("problem_description"):
                            st.warning("- è¦è§£æ±ºçš„å…·é«”å•é¡Œ")
                        if not requirements.get("stage_1", {}).get("target_users"):
                            st.warning("- ç›®æ¨™ç”¨æˆ¶æè¿°")
                        if not requirements.get("stage_2", {}).get("measurable_metrics"):
                            st.warning("- å¯é‡åŒ–çš„æŒ‡æ¨™")
                        if not requirements.get("stage_2", {}).get("mvp_features"):
                            st.warning("- MVP æ ¸å¿ƒåŠŸèƒ½")

                st.rerun()

    with tab2:
        st.header("ğŸ“‹ åˆç‰ˆPRD")

        # ä½¿ç”¨ç‹€æ…‹è®Šé‡è€Œä¸æ˜¯æ–‡å­—åŒ¹é…
        requirements_completed = st.session_state.requirements_completed

        # é¡¯ç¤ºç‹€æ…‹æç¤º
        col1, col2 = st.columns(2)
        with col1:
            if requirements_completed:
                st.success("âœ… éœ€æ±‚æ”¶é›†å®Œæˆ")
            else:
                st.info("â³ ç­‰å¾…éœ€æ±‚æ”¶é›†å®Œæˆ")

        with col2:
            if st.session_state.selected_mode:
                st.success(f"âœ… å·²é¸æ“‡ï¼š{st.session_state.selected_mode}")
            else:
                st.warning("âš ï¸ è«‹é¸æ“‡é–‹ç™¼æ¨¡å¼")

        st.divider()

        # è‡ªå‹•ç”Ÿæˆ PRDï¼ˆå¦‚æœæ¢ä»¶æ»¿è¶³ä¸”é‚„æ²’æœ‰ç”Ÿæˆï¼‰
        if requirements_completed and st.session_state.selected_mode and not st.session_state.current_prd:
            with st.spinner(f"æ­£åœ¨æ ¹æ“š {st.session_state.selected_mode} æ¨¡å¼ç”Ÿæˆ PRD..."):
                # å¯¦éš›èª¿ç”¨å°æ‡‰çš„ PRD Agent
                prd_content = run_async(generate_prd_with_agent(
                    st.session_state.selected_mode,
                    st.session_state.requirements
                ))
                st.session_state.current_prd = prd_content
                st.rerun()

        # é¡¯ç¤ºæç¤ºè¨Šæ¯ï¼ˆå¦‚æœæ¢ä»¶ä¸æ»¿è¶³ï¼‰
        if not requirements_completed or not st.session_state.selected_mode:
            warning_messages = []
            if not requirements_completed:
                warning_messages.append("âš ï¸ å°šæœªå®Œæˆéœ€æ±‚æ”¶é›†ï¼Œè«‹å…ˆå‰å¾€ã€éœ€æ±‚æ”¶é›†ã€æ¨™ç±¤å®Œæˆå•ç­”")
            if not st.session_state.selected_mode:
                warning_messages.append("âš ï¸ å°šæœªé¸æ“‡é–‹ç™¼æ¨¡å¼ï¼Œè«‹åœ¨å·¦å´é‚Šæ¬„é¸æ“‡ PRD é–‹ç™¼æ¨¡å¼")

            for msg in warning_messages:
                st.warning(msg)

        # PRD é¡¯ç¤ºå’Œç·¨è¼¯å€åŸŸï¼ˆç¸½æ˜¯é¡¯ç¤º TEXTAREAï¼‰
        st.subheader("ğŸ“„ PRD å…§å®¹")

        # é¡¯ç¤º PRD çš„ TEXTAREA
        prd_content = st.text_area(
            "PRD å…§å®¹ï¼ˆå¯ç·¨è¼¯ï¼‰",
            value=st.session_state.current_prd if st.session_state.current_prd else "# ç”¢å“éœ€æ±‚æ–‡æª” (PRD)\n\nç­‰å¾…ç”Ÿæˆ...",
            height=500,
            help="æ‚¨å¯ä»¥ç›´æ¥ç·¨è¼¯ PRD å…§å®¹",
            label_visibility="collapsed",
            key="prd_textarea"
        )

        # ä¿å­˜ç·¨è¼¯å…§å®¹ï¼ˆåªåœ¨æœ‰å…§å®¹æ™‚ï¼‰
        if st.session_state.current_prd and prd_content != st.session_state.current_prd:
            st.session_state.current_prd = prd_content

        st.divider()

        # å®Œæ•´æ€§æª¢æŸ¥æŒ‰éˆ•ã€AIå‡ç´šæª¢æŸ¥è¡¨æŒ‰éˆ•ã€ç”Ÿæˆå¤šç‰ˆæœ¬PRDæŒ‰éˆ•
        col1, col2, col3, col4 = st.columns([1, 1.5, 1.5, 1])
        with col1:
            check_button = st.button("ğŸ” å®Œæ•´æ€§æª¢æŸ¥", type="primary", use_container_width=True)

        with col2:
            ai_upgrade_button = st.button("âœ… AIå‡ç´šæª¢æŸ¥è¡¨", type="secondary", use_container_width=True)

        with col3:
            generate_multi_button = st.button("ğŸš€ ç”Ÿæˆå¤šç‰ˆæœ¬ PRD", type="secondary", use_container_width=True)

        if check_button:
            if not st.session_state.current_prd:
                st.error("âŒ è«‹å…ˆç”Ÿæˆ PRD å†é€²è¡Œæª¢æŸ¥")
            else:
                with st.spinner("æ­£åœ¨æª¢æŸ¥ PRD å®Œæ•´æ€§..."):
                    from google.adk.models.lite_llm import LiteLlm
                    from google.genai import types

                    # å‰µå»ºè‡¨æ™‚æ¨¡å‹å¯¦ä¾‹
                    model = LiteLlm(
                        model="gpt-4o",
                        api_base=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                        api_key=os.getenv("OPENAI_API_KEY")
                    )

                    check_prompt = f"""è«‹ä»¥å°ˆæ¥­ç”¢å“ç¶“ç†å’Œå·¥ç¨‹å¸«çš„è§’åº¦ï¼Œæª¢æŸ¥é€™ä»½ PRD çš„å®Œæ•´æ€§ï¼Œä¸¦å›ç­”ä»¥ä¸‹å•é¡Œï¼š

PRD å…§å®¹ï¼š
{st.session_state.current_prd}

è«‹åˆ†æä¸¦å›ç­”ï¼š
1. æœ‰å“ªäº›é‡è¦ä½†æ²’æåˆ°çš„éƒ¨åˆ†ï¼Ÿ
2. æœ‰å“ªäº›å¯èƒ½çš„é¢¨éšªæ²’è€ƒæ…®åˆ°ï¼Ÿ
3. æœ‰å“ªäº›åœ°æ–¹å¯èƒ½é€ æˆç†è§£æ­§ç¾©ï¼Ÿ
4. å¦‚æœä½ æ˜¯å·¥ç¨‹å¸«ï¼Œé‚„éœ€è¦çŸ¥é“ä»€éº¼æ‰èƒ½é–‹å§‹é–‹ç™¼ï¼Ÿ

è«‹ä½¿ç”¨ Markdown æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹çµæ§‹ï¼š

## å®Œæ•´æ€§æª¢æŸ¥çµæœ

### 1. é‡è¦ä½†æ²’æåˆ°çš„éƒ¨åˆ†
[åˆ—å‡ºç¼ºå¤±çš„é‡è¦éƒ¨åˆ†]

### 2. å¯èƒ½çš„é¢¨éšª
[åˆ—å‡ºæ½›åœ¨é¢¨éšª]

### 3. å¯èƒ½é€ æˆæ­§ç¾©çš„éƒ¨åˆ†
[åˆ—å‡ºæ¨¡ç³Šä¸æ¸…çš„æè¿°]

### 4. å·¥ç¨‹å¸«éœ€è¦çš„é¡å¤–ä¿¡æ¯
[åˆ—å‡ºé–‹ç™¼æ‰€éœ€çš„é¡å¤–è³‡è¨Š]

### æ”¹é€²å»ºè­°
[æä¾›å…·é«”çš„æ”¹é€²å»ºè­°]

è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚"""

                    try:
                        # èª¿ç”¨ LLM é€²è¡Œæª¢æŸ¥
                        content = types.Content(
                            role='user',
                            parts=[types.Part(text=check_prompt)]
                        )

                        response = model.generate_content(contents=[content])
                        response_text = response.text.strip()

                        # ä¿å­˜æª¢æŸ¥çµæœ
                        st.session_state.prd_check_results = response_text
                        st.rerun()

                    except Exception as e:
                        logger.error(f"PRD å®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: {str(e)}")
                        st.error(f"æª¢æŸ¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

        # é¡¯ç¤ºæª¢æŸ¥çµæœ
        if "prd_check_results" in st.session_state and st.session_state.prd_check_results:
            st.divider()
            st.subheader("ğŸ“Š æª¢æŸ¥çµæœ")
            st.markdown(st.session_state.prd_check_results)

            # è‡ªå‹•æ›´æ–° PRD æŒ‰éˆ•
            st.divider()
            if st.button("ğŸ”„ è‡ªå‹•æ›´æ–° PRD", key="auto_update_completeness", type="primary", use_container_width=True):
                with st.spinner("ğŸ”„ æ­£åœ¨æ ¹æ“šå»ºè­°è‡ªå‹•æ›´æ–° PRD..."):
                    from google.adk.models.lite_llm import LiteLlm
                    from google.genai import types

                    try:
                        # å‰µå»ºæ¨¡å‹
                        model = LiteLlm(
                            model="gpt-4o",
                            api_base=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                            api_key=os.getenv("OPENAI_API_KEY")
                        )

                        # æ§‹å»ºæç¤ºè©
                        update_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹å®Œæ•´æ€§æª¢æŸ¥çš„æ”¹é€²å»ºè­°ï¼Œä¿®æ­£ PRD å…§å®¹ã€‚

åŸå§‹ PRDï¼š
{st.session_state.current_prd}

æ”¹é€²å»ºè­°ï¼š
{st.session_state.prd_check_results}

è«‹ç”Ÿæˆä¿®æ­£å¾Œçš„å®Œæ•´ PRDï¼Œè¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„ Markdown çµæ§‹å’Œæ ¼å¼
2. åªä¿®æ”¹éœ€è¦æ”¹é€²çš„éƒ¨åˆ†
3. è£œå……ç¼ºå¤±çš„é‡è¦å…§å®¹
4. è§£æ±ºå»ºè­°ä¸­æŒ‡å‡ºçš„å•é¡Œ
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡º

è«‹ç›´æ¥è¼¸å‡ºä¿®æ­£å¾Œçš„å®Œæ•´ PRDï¼Œä¸è¦å…¶ä»–èªªæ˜ã€‚"""

                        # èª¿ç”¨ AI
                        content = types.Content(
                            role='user',
                            parts=[types.Part(text=update_prompt)]
                        )

                        response = model.generate_content(contents=[content])
                        updated_prd = response.text.strip()

                        # æ›´æ–° PRD
                        st.session_state.current_prd = updated_prd
                        st.success("âœ… PRD å·²æ ¹æ“šå®Œæ•´æ€§æª¢æŸ¥å»ºè­°è‡ªå‹•æ›´æ–°ï¼è«‹æŸ¥çœ‹ä¸Šæ–¹ PRD å…§å®¹ã€‚")
                        st.rerun()

                    except Exception as e:
                        logger.error(f"è‡ªå‹•æ›´æ–° PRD å¤±æ•—: {str(e)}")
                        st.error(f"æ›´æ–°éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

        # ç”Ÿæˆå¤šç‰ˆæœ¬ PRD æŒ‰éˆ•é‚è¼¯
        if generate_multi_button:
            if not st.session_state.current_prd:
                st.error("âŒ è«‹å…ˆç”Ÿæˆåˆç‰ˆ PRD")
            else:
                with st.spinner("ğŸš€ æ­£åœ¨ç”Ÿæˆä¸‰å€‹ç‰ˆæœ¬çš„ PRD..."):
                    # èª¿ç”¨ MultiVersionGenerator
                    generator = MultiVersionGenerator()
                    versions = run_async(generator.generate_versions(st.session_state.current_prd))

                    # ä¿å­˜åˆ° session state
                    st.session_state.version_comparison = versions

                    st.success("âœ… ä¸‰ç‰ˆæœ¬ PRD ç”Ÿæˆå®Œæˆï¼è«‹é»æ“Šä¸Šæ–¹ã€ŒğŸ“Š å¤šç‰ˆæœ¬PRDã€æ¨™ç±¤æŸ¥çœ‹çµæœã€‚")
                    st.rerun()

        # AIå‡ç´šæª¢æŸ¥è¡¨æŒ‰éˆ•é‚è¼¯
        if ai_upgrade_button:
            if not st.session_state.current_prd:
                st.error("âŒ è«‹å…ˆç”Ÿæˆåˆç‰ˆ PRD")
            else:
                with st.spinner("ğŸ” æ­£åœ¨é€²è¡Œ AI å‡ç´šæª¢æŸ¥..."):
                    from google.adk.models.lite_llm import LiteLlm
                    from google.genai import types

                    # å‰µå»ºè‡¨æ™‚æ¨¡å‹å¯¦ä¾‹
                    model = LiteLlm(
                        model="gpt-4o",
                        api_base=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                        api_key=os.getenv("OPENAI_API_KEY")
                    )

                    check_prompt = f"""è«‹åˆ†æä»¥ä¸‹ PRDï¼Œæª¢æŸ¥æ˜¯å¦ç¬¦åˆ AI å‹å–„çš„ PRD æ¨™æº–ã€‚

PRD å…§å®¹ï¼š
{st.session_state.current_prd}

è«‹æª¢æŸ¥ä»¥ä¸‹ 13 å€‹é …ç›®ï¼Œä¸¦ä»¥ JSON æ ¼å¼å›æ‡‰ã€‚æ¯å€‹é …ç›®åŒ…å«å…©å€‹å­—æ®µï¼š
- "passed": true/falseï¼ˆæ˜¯å¦ç¬¦åˆæ¨™æº–ï¼‰
- "suggestion": "å…·é«”æ”¹é€²å»ºè­°"ï¼ˆå¦‚æœ passed ç‚º falseï¼Œæä¾›å…·é«”å»ºè­°ï¼›å¦‚æœç‚º trueï¼Œå¡«ç©ºå­—ä¸²ï¼‰

JSON æ ¼å¼ç¯„ä¾‹ï¼š
{{
  "basic": {{
    "problem_statement": {{
      "passed": false,
      "suggestion": "å»ºè­°åœ¨ PRD é–‹é ­è£œå……æ˜ç¢ºçš„å•é¡Œé™³è¿°ï¼Œèªªæ˜è¦è§£æ±ºä»€éº¼å…·é«”å•é¡Œ"
    }},
    "success_metrics": {{
      "passed": true,
      "suggestion": ""
    }}
  }}
}}

è«‹æª¢æŸ¥ä»¥ä¸‹é …ç›®ï¼š

åŸºæœ¬è¦ç´ ï¼š
1. problem_statement - æœ‰æ˜ç¢ºçš„å•é¡Œé™³è¿°
2. success_metrics - æœ‰å¯é‡åŒ–çš„æˆåŠŸæŒ‡æ¨™
3. user_scenarios - æœ‰å…·é«”çš„ç”¨æˆ¶å ´æ™¯
4. priority - æœ‰å„ªå…ˆç´šæ’åº
5. timeline - æœ‰æ™‚ç¨‹é ä¼°

AI å‹å–„è¦ç´ ï¼š
6. structured_format - ä½¿ç”¨çµæ§‹åŒ–æ ¼å¼ï¼ˆJSON/YAML/Markdownï¼‰
7. term_definition - å°ˆæœ‰åè©æœ‰æ˜ç¢ºå®šç¾©
8. sample_data - ç¯„ä¾‹è³‡æ–™å®Œæ•´

å¯åŸ·è¡Œè¦ç´ ï¼š
9. user_story - å¯ä»¥ç›´æ¥è½‰æˆ User Story
10. test_cases - å¯ä»¥ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹
11. api_spec - å¯ä»¥ç”¢ç”Ÿ API è¦æ ¼
12. wireframe - å¯ä»¥è£½ä½œ Wireframe
13. time_estimate - å¯ä»¥ä¼°ç®—é–‹ç™¼æ™‚é–“

è«‹ç”¨ç¹é«”ä¸­æ–‡æä¾›å»ºè­°ï¼Œåªå›æ‡‰ JSON æ ¼å¼ï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—ã€‚"""

                    try:
                        # èª¿ç”¨ AI é€²è¡Œæª¢æŸ¥
                        content = types.Content(
                            role='user',
                            parts=[types.Part(text=check_prompt)]
                        )

                        response = model.generate_content(contents=[content])
                        response_text = response.text.strip()

                        # å˜—è©¦è§£æ JSON
                        import re
                        json_match = re.search(r'\{[\s\S]*\}', response_text)
                        if json_match:
                            checklist_data = json.loads(json_match.group())
                            st.session_state.ai_upgrade_checklist = checklist_data
                        else:
                            st.session_state.ai_upgrade_checklist = None
                            st.error("ç„¡æ³•è§£ææª¢æŸ¥çµæœ")

                        st.rerun()

                    except Exception as e:
                        logger.error(f"AIå‡ç´šæª¢æŸ¥å¤±æ•—: {str(e)}")
                        st.error(f"æª¢æŸ¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

        # é¡¯ç¤º AI å‡ç´šæª¢æŸ¥çµæœ
        if "ai_upgrade_checklist" in st.session_state and st.session_state.ai_upgrade_checklist:
            st.divider()
            st.subheader("âœ… AI å‡ç´šæª¢æŸ¥è¡¨")

            checklist = st.session_state.ai_upgrade_checklist

            # åŸºæœ¬è¦ç´ 
            st.markdown("#### ğŸ“‹ åŸºæœ¬è¦ç´ ")

            # å•é¡Œé™³è¿°
            problem_statement = checklist.get("basic", {}).get("problem_statement", {})
            st.checkbox("æœ‰æ˜ç¢ºçš„å•é¡Œé™³è¿°ï¼ˆProblem Statementï¼‰",
                       value=problem_statement.get("passed", False),
                       disabled=True, key="check_basic_1")
            if not problem_statement.get("passed", False) and problem_statement.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {problem_statement.get('suggestion')}")

            # æˆåŠŸæŒ‡æ¨™
            success_metrics = checklist.get("basic", {}).get("success_metrics", {})
            st.checkbox("æœ‰å¯é‡åŒ–çš„æˆåŠŸæŒ‡æ¨™ï¼ˆSuccess Metricsï¼‰",
                       value=success_metrics.get("passed", False),
                       disabled=True, key="check_basic_2")
            if not success_metrics.get("passed", False) and success_metrics.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {success_metrics.get('suggestion')}")

            # ç”¨æˆ¶å ´æ™¯
            user_scenarios = checklist.get("basic", {}).get("user_scenarios", {})
            st.checkbox("æœ‰å…·é«”çš„ç”¨æˆ¶å ´æ™¯ï¼ˆUser Scenariosï¼‰",
                       value=user_scenarios.get("passed", False),
                       disabled=True, key="check_basic_3")
            if not user_scenarios.get("passed", False) and user_scenarios.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {user_scenarios.get('suggestion')}")

            # å„ªå…ˆç´šæ’åº
            priority = checklist.get("basic", {}).get("priority", {})
            st.checkbox("æœ‰å„ªå…ˆç´šæ’åºï¼ˆPriorityï¼‰",
                       value=priority.get("passed", False),
                       disabled=True, key="check_basic_4")
            if not priority.get("passed", False) and priority.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {priority.get('suggestion')}")

            # æ™‚ç¨‹é ä¼°
            timeline = checklist.get("basic", {}).get("timeline", {})
            st.checkbox("æœ‰æ™‚ç¨‹é ä¼°ï¼ˆTimelineï¼‰",
                       value=timeline.get("passed", False),
                       disabled=True, key="check_basic_5")
            if not timeline.get("passed", False) and timeline.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {timeline.get('suggestion')}")

            # AI å‹å–„è¦ç´ 
            st.markdown("#### ğŸ¤– AI å‹å–„è¦ç´ ")

            # çµæ§‹åŒ–æ ¼å¼
            structured_format = checklist.get("ai_friendly", {}).get("structured_format", {})
            st.checkbox("ä½¿ç”¨çµæ§‹åŒ–æ ¼å¼ï¼ˆJSON/YAML/Markdownï¼‰",
                       value=structured_format.get("passed", False),
                       disabled=True, key="check_ai_1")
            if not structured_format.get("passed", False) and structured_format.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {structured_format.get('suggestion')}")

            # å°ˆæœ‰åè©å®šç¾©
            term_definition = checklist.get("ai_friendly", {}).get("term_definition", {})
            st.checkbox("å°ˆæœ‰åè©æœ‰æ˜ç¢ºå®šç¾©",
                       value=term_definition.get("passed", False),
                       disabled=True, key="check_ai_2")
            if not term_definition.get("passed", False) and term_definition.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {term_definition.get('suggestion')}")

            # ç¯„ä¾‹è³‡æ–™
            sample_data = checklist.get("ai_friendly", {}).get("sample_data", {})
            st.checkbox("ç¯„ä¾‹è³‡æ–™å®Œæ•´",
                       value=sample_data.get("passed", False),
                       disabled=True, key="check_ai_3")
            if not sample_data.get("passed", False) and sample_data.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {sample_data.get('suggestion')}")

            # å¯åŸ·è¡Œè¦ç´ 
            st.markdown("#### âš¡ å¯åŸ·è¡Œè¦ç´ ")

            # User Story
            user_story = checklist.get("executable", {}).get("user_story", {})
            st.checkbox("å¯ä»¥ç›´æ¥è½‰æˆ User Story",
                       value=user_story.get("passed", False),
                       disabled=True, key="check_exec_1")
            if not user_story.get("passed", False) and user_story.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {user_story.get('suggestion')}")

            # æ¸¬è©¦æ¡ˆä¾‹
            test_cases = checklist.get("executable", {}).get("test_cases", {})
            st.checkbox("å¯ä»¥ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹",
                       value=test_cases.get("passed", False),
                       disabled=True, key="check_exec_2")
            if not test_cases.get("passed", False) and test_cases.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {test_cases.get('suggestion')}")

            # API è¦æ ¼
            api_spec = checklist.get("executable", {}).get("api_spec", {})
            st.checkbox("å¯ä»¥ç”¢ç”Ÿ API è¦æ ¼",
                       value=api_spec.get("passed", False),
                       disabled=True, key="check_exec_3")
            if not api_spec.get("passed", False) and api_spec.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {api_spec.get('suggestion')}")

            # Wireframe
            wireframe = checklist.get("executable", {}).get("wireframe", {})
            st.checkbox("å¯ä»¥è£½ä½œ Wireframe",
                       value=wireframe.get("passed", False),
                       disabled=True, key="check_exec_4")
            if not wireframe.get("passed", False) and wireframe.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {wireframe.get('suggestion')}")

            # é–‹ç™¼æ™‚é–“ä¼°ç®—
            time_estimate = checklist.get("executable", {}).get("time_estimate", {})
            st.checkbox("å¯ä»¥ä¼°ç®—é–‹ç™¼æ™‚é–“",
                       value=time_estimate.get("passed", False),
                       disabled=True, key="check_exec_5")
            if not time_estimate.get("passed", False) and time_estimate.get("suggestion"):
                st.markdown(f"ğŸ’¡ **å»ºè­°ï¼š** {time_estimate.get('suggestion')}")

            # è‡ªå‹•æ›´æ–° PRD æŒ‰éˆ•
            st.divider()
            if st.button("ğŸ”„ è‡ªå‹•æ›´æ–° PRD", key="auto_update_ai_checklist", type="primary", use_container_width=True):
                with st.spinner("ğŸ”„ æ­£åœ¨æ ¹æ“š AI å‡ç´šæª¢æŸ¥å»ºè­°è‡ªå‹•æ›´æ–° PRD..."):
                    from google.adk.models.lite_llm import LiteLlm
                    from google.genai import types

                    try:
                        # æå–æ‰€æœ‰æœªé€šéé …ç›®çš„å»ºè­°
                        suggestions = []
                        checklist = st.session_state.ai_upgrade_checklist

                        for category in ["basic", "ai_friendly", "executable"]:
                            for item_name, item_data in checklist.get(category, {}).items():
                                if isinstance(item_data, dict):
                                    if not item_data.get("passed", False) and item_data.get("suggestion"):
                                        suggestions.append(item_data.get("suggestion"))

                        # æ§‹å»ºå»ºè­°æ–‡æœ¬
                        if suggestions:
                            suggestions_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(suggestions)])
                        else:
                            st.info("âœ… æ‰€æœ‰æª¢æŸ¥é …ç›®éƒ½å·²é€šéï¼Œç„¡éœ€æ›´æ–°ï¼")
                            st.stop()

                        # å‰µå»ºæ¨¡å‹
                        model = LiteLlm(
                            model="gpt-4o",
                            api_base=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                            api_key=os.getenv("OPENAI_API_KEY")
                        )

                        # æ§‹å»ºæç¤ºè©
                        update_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ AI å‡ç´šæª¢æŸ¥çš„æ”¹é€²å»ºè­°ï¼Œä¿®æ­£ PRD å…§å®¹ï¼Œä½¿å…¶ç¬¦åˆ AI å‹å–„æ¨™æº–ã€‚

åŸå§‹ PRDï¼š
{st.session_state.current_prd}

éœ€è¦æ”¹é€²çš„é …ç›®ï¼š
{suggestions_text}

è«‹ç”Ÿæˆä¿®æ­£å¾Œçš„å®Œæ•´ PRDï¼Œè¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„ Markdown çµæ§‹å’Œæ ¼å¼
2. æ ¹æ“šæ¯å€‹å»ºè­°é€²è¡Œé‡å°æ€§æ”¹é€²
3. ç¢ºä¿ PRD ç¬¦åˆ AI å‹å–„æ¨™æº–ï¼ˆçµæ§‹åŒ–ã€æ˜ç¢ºå®šç¾©ã€å¯åŸ·è¡Œï¼‰
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡º

è«‹ç›´æ¥è¼¸å‡ºä¿®æ­£å¾Œçš„å®Œæ•´ PRDï¼Œä¸è¦å…¶ä»–èªªæ˜ã€‚"""

                        # èª¿ç”¨ AI
                        content = types.Content(
                            role='user',
                            parts=[types.Part(text=update_prompt)]
                        )

                        response = model.generate_content(contents=[content])
                        updated_prd = response.text.strip()

                        # æ›´æ–° PRD
                        st.session_state.current_prd = updated_prd
                        st.success("âœ… PRD å·²æ ¹æ“š AI å‡ç´šæª¢æŸ¥å»ºè­°è‡ªå‹•æ›´æ–°ï¼è«‹æŸ¥çœ‹ä¸Šæ–¹ PRD å…§å®¹ã€‚")
                        st.rerun()

                    except Exception as e:
                        logger.error(f"è‡ªå‹•æ›´æ–° PRD å¤±æ•—: {str(e)}")
                        st.error(f"æ›´æ–°éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


    with tab3:
        st.header("ğŸ“Š å¤šç‰ˆæœ¬PRD")

        if not st.session_state.current_prd:
            st.warning("â³ è«‹å…ˆåœ¨ã€åˆç‰ˆPRDã€ä¸­ç”Ÿæˆ PRD")
        else:
            st.info("ç”Ÿæˆä¸‰å€‹ç‰ˆæœ¬çš„ PRDï¼šMVPç‰ˆã€æ¨™æº–ç‰ˆã€ç†æƒ³ç‰ˆï¼Œä¸¦æä¾›æ¯”è¼ƒåˆ†æ")

            col1, col2 = st.columns([3, 1])
            with col2:
                if st.button("ğŸš€ ç”Ÿæˆä¸‰ç‰ˆæœ¬ PRD", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆä¸‰å€‹ç‰ˆæœ¬çš„ PRD..."):
                        # èª¿ç”¨ MultiVersionGenerator
                        generator = MultiVersionGenerator()
                        versions = run_async(generator.generate_versions(st.session_state.current_prd))
                        st.session_state.version_comparison = versions
                        st.success("âœ… ä¸‰ç‰ˆæœ¬ PRD ç”Ÿæˆå®Œæˆï¼")
                        st.rerun()

            st.divider()

            # é¡¯ç¤ºä¸‰ç‰ˆæœ¬æ¯”è¼ƒ
            if st.session_state.version_comparison:
                st.subheader("ğŸ“Š ç‰ˆæœ¬æ¯”è¼ƒåˆ†æ")

                # æ¯”è¼ƒè¡¨æ ¼
                comparison_data = {
                    "æ¯”è¼ƒé …ç›®": ["åŠŸèƒ½ç¯„åœ", "é–‹ç™¼æˆæœ¬", "æŠ€è¡“é›£åº¦", "é–‹ç™¼æ™‚é–“", "é æœŸæ•ˆç›Š", "é¢¨éšªç­‰ç´š"],
                    "MVPç‰ˆ": ["æ ¸å¿ƒåŠŸèƒ½", "ä½ï¼ˆ< 10è¬ï¼‰", "ç°¡å–®", "7å¤©", "å¿«é€Ÿé©—è­‰", "ä½"],
                    "æ¨™æº–ç‰ˆ": ["ä¸»è¦åŠŸèƒ½", "ä¸­ï¼ˆ10-50è¬ï¼‰", "ä¸­ç­‰", "1å€‹æœˆ", "å•†æ¥­åŒ–å°±ç·’", "ä¸­"],
                    "ç†æƒ³ç‰ˆ": ["å®Œæ•´åŠŸèƒ½", "é«˜ï¼ˆ> 50è¬ï¼‰", "è¤‡é›œ", "ä¸é™", "æ¥µè‡´é«”é©—", "é«˜"]
                }

                st.dataframe(comparison_data, use_container_width=True)

                st.divider()

                # ä¸‰ç‰ˆæœ¬è©³ç´°å…§å®¹
                st.subheader("ğŸ“‹ è©³ç´° PRD å…§å®¹")

                tab_mvp, tab_standard, tab_ideal = st.tabs(["ğŸƒâ€â™‚ï¸ MVPç‰ˆ", "ğŸ¯ æ¨™æº–ç‰ˆ", "â­ ç†æƒ³ç‰ˆ"])

                with tab_mvp:
                    st.text_area(
                        "MVPç‰ˆ PRD",
                        value=st.session_state.version_comparison["mvp"],
                        height=300,
                        key="mvp_prd"
                    )

                with tab_standard:
                    st.text_area(
                        "æ¨™æº–ç‰ˆ PRD",
                        value=st.session_state.version_comparison["standard"],
                        height=300,
                        key="standard_prd"
                    )

                with tab_ideal:
                    st.text_area(
                        "ç†æƒ³ç‰ˆ PRD",
                        value=st.session_state.version_comparison["ideal"],
                        height=300,
                        key="ideal_prd"
                    )

                # å°å‡ºåŠŸèƒ½
                st.divider()
                st.subheader("ğŸ“¤ å°å‡ºé¸é …")

                export_col1, export_col2, export_col3, export_col4 = st.columns(4)

                with export_col1:
                    # å°å‡º Markdown
                    combined_content = f"""# å®Œæ•´ PRD æ–‡æª”

## åŸå§‹éœ€æ±‚
{json.dumps(st.session_state.requirements, ensure_ascii=False, indent=2)}

## åˆç‰ˆ PRD
{st.session_state.current_prd}

## MVPç‰ˆ
{st.session_state.version_comparison["mvp"]}

## æ¨™æº–ç‰ˆ
{st.session_state.version_comparison["standard"]}

## ç†æƒ³ç‰ˆ
{st.session_state.version_comparison["ideal"]}
"""
                    st.download_button(
                        label="ğŸ“„ å°å‡º Markdown",
                        data=combined_content,
                        file_name="complete_prd.md",
                        mime="text/markdown"
                    )

                with export_col2:
                    # å°å‡º JSON
                    json_data = {
                        "requirements": st.session_state.requirements,
                        "initial_prd": st.session_state.current_prd,
                        "versions": st.session_state.version_comparison,
                        "review_results": st.session_state.review_results
                    }
                    st.download_button(
                        label="ğŸ“Š å°å‡º JSON",
                        data=json.dumps(json_data, ensure_ascii=False, indent=2),
                        file_name="prd_data.json",
                        mime="application/json"
                    )

                with export_col3:
                    if st.button("ğŸ“‹ è¤‡è£½å…§å®¹"):
                        st.code(combined_content, language="markdown")
                        st.success("âœ… å…§å®¹å·²é¡¯ç¤ºï¼Œè«‹æ‰‹å‹•è¤‡è£½")

                with export_col4:
                    if st.button("ğŸ”— åˆ†äº«é€£çµ"):
                        # TODO: å¯¦ç¾åˆ†äº«åŠŸèƒ½
                        st.success("ğŸ”— åˆ†äº«é€£çµï¼šhttps://...")
                        st.info("åˆ†äº«åŠŸèƒ½é–‹ç™¼ä¸­...")

if __name__ == "__main__":
    main()